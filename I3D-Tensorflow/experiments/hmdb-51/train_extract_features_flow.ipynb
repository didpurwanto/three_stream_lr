{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lala\n",
      "Number of test videos=1530\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c02eafaed4f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c02eafaed4f2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c02eafaed4f2>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_soft_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         )\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_checkpoint_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_model_save_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, op, message)\u001b[0m\n\u001b[1;32m    330\u001b[0m   \"\"\"\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0;34m\"\"\"Creates a `ResourceExhaustedError`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     super(ResourceExhaustedError, self).__init__(node_def, op, message,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copyright 2015 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Trains and Evaluates the MNIST network using a feed dictionary.\"\"\"\n",
    "# pylint: disable=missing-docstring\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import os\n",
    "import time\n",
    "import numpy\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import input_test as input_test\n",
    "import math\n",
    "import numpy as np\n",
    "from i3d import InceptionI3d\n",
    "from utils import *\n",
    "\n",
    "# Basic model parameters as external flags.\n",
    "flags = tf.app.flags\n",
    "gpu_num = 1\n",
    "flags.DEFINE_integer('batch_size', 1, 'Batch size.')\n",
    "flags.DEFINE_integer('num_frame_per_clib', 64, 'Nummber of frames per clib')\n",
    "flags.DEFINE_integer('crop_size', 224, 'Crop_size')\n",
    "flags.DEFINE_integer('rgb_channels', 3, 'Channels for input')\n",
    "flags.DEFINE_integer('classics', 51, 'The num of class')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "outfile = './flow_scratch_data_split1/test64/'\n",
    "\n",
    "print(\"lala\")\n",
    "\n",
    "def run_training():\n",
    "    # Get the sets of images and labels for training, validation, and\n",
    "    # Tell TensorFlow that the model will be built into the default Graph.\n",
    "    pre_model_save_dir = \"./models/HMDB_scratch_fix/flow_scratch_20000_6_64_0.0001_decay_low_split1\"\n",
    "    test_list_file = '../../list/hmdb_list/testlist1.list'\n",
    "    file = list(open(test_list_file, 'r'))\n",
    "    num_test_videos = len(file)\n",
    "    print(\"Number of test videos={}\".format(num_test_videos))\n",
    "    with tf.Graph().as_default():\n",
    "        rgb_images_placeholder, flow_images_placeholder, labels_placeholder, is_training = placeholder_inputs(\n",
    "                        FLAGS.batch_size * gpu_num,\n",
    "                        FLAGS.num_frame_per_clib,\n",
    "                        FLAGS.crop_size,\n",
    "                        FLAGS.rgb_channels\n",
    "                        )\n",
    "\n",
    "        with tf.variable_scope('Flow'):\n",
    "            logit, _ = InceptionI3d(\n",
    "                                num_classes=FLAGS.classics,\n",
    "                                spatial_squeeze=True,\n",
    "                                final_endpoint='Mixed_5c',\n",
    "                                name='inception_i3d'\n",
    "                                )(flow_images_placeholder, is_training)\n",
    "        norm_score = tf.nn.softmax(logit)\n",
    "\n",
    "        # Create a saver for writing training checkpoints.\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Create a session for running Ops on the Graph.\n",
    "        sess = tf.Session(\n",
    "                        config=tf.ConfigProto(allow_soft_placement=True)\n",
    "                        )\n",
    "        sess.run(init)\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(pre_model_save_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print(ckpt.model_checkpoint_path)\n",
    "        print (\"loading checkpoint %s,waiting......\" % ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print (\"load complete!\")\n",
    "\n",
    "    all_steps = num_test_videos\n",
    "    top1_list = []\n",
    "    for step in xrange(all_steps):\n",
    "        start_time = time.time()\n",
    "        s_index = 0\n",
    "        predicts = []\n",
    "        data = {}\n",
    "        data_new = np.array([])\n",
    "        top1 = False\n",
    "        while True:\n",
    "            _, val_images, val_labels, s_index, is_end = input_test.read_clip_and_label(\n",
    "                            filename=file[step],\n",
    "                            batch_size=FLAGS.batch_size * gpu_num,\n",
    "                            s_index=s_index,\n",
    "                            num_frames_per_clip=FLAGS.num_frame_per_clib,\n",
    "                            crop_size=FLAGS.crop_size,\n",
    "                            )\n",
    "            data_features = sess.run(norm_score,\n",
    "                               feed_dict={\n",
    "                                            flow_images_placeholder: val_images,\n",
    "                                            labels_placeholder: val_labels,\n",
    "                                            is_training: False\n",
    "                                            })\n",
    "            \n",
    "            temp = np.mean(data_features, axis=2)\n",
    "            tmp = np.mean(temp, axis=2)\n",
    "            tmp = np.squeeze(tmp)\n",
    "            print(\"lllllllllllllllllllll\")\n",
    "            print(data_features.shape)\n",
    "            # print(temp.shape)\n",
    "            # print(tmp.shape)\n",
    "\n",
    "            if data_new.shape[0] == 0:\n",
    "                data_new = tmp\n",
    "            else:\n",
    "                data_new = np.concatenate([data_new,tmp])\n",
    "\n",
    "            labell = np.zeros((1,51))\n",
    "            labell[0,int(val_labels)] = 1\n",
    "\n",
    "            #print(labell)\n",
    "\n",
    "            if is_end:\n",
    "                ndata = int(data_new.shape[0])\n",
    "                \n",
    "                \n",
    "                if ndata <=64:\n",
    "                    data_new = np.concatenate([data_new,data_new],  axis=0)\n",
    "                    data_new = np.concatenate([data_new,data_new],  axis=0)\n",
    "                    ndata = int(data_new.shape[0])\n",
    "                \n",
    "                sampling = ndata/64\n",
    "                print(sampling)\n",
    "                print(data_new.shape)\n",
    "                ndata2 = data_new[0:64*sampling,:]\n",
    "                ndata3 = ndata2[0::sampling,:]\n",
    "                print(ndata3.shape)\n",
    "\n",
    "                data['feat'] = ndata3\n",
    "                data['label'] = labell\n",
    "                \n",
    "                temp = file[step].split(\"/\")\n",
    "                namefile = temp[6].split(\" \")\n",
    "                print(namefile[0])\n",
    "\n",
    "                datasave = outfile+namefile[0]\n",
    "                print(datasave)\n",
    "                np.save(datasave, data)\n",
    "                break\n",
    "        \n",
    "\n",
    "\n",
    "def main(_):\n",
    "    run_training()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
